 # coding: utf-8
'''
Deployment script for {{cookiecutter.domain}}. Though specific to 
{{cookiecutter.domain}}, the script is largely data driven and the 
required data is defined at the top of this file.

Note that this script is dependent upon the deployment model as defined by the
deploy-django project @ https://github.com/harikvpy/deploy-django.
'''
import os
import tempfile
import json
from pathlib import Path
import datetime

from fabric import Connection, task
from invocations import console

SUDO_PASSWORD = os.environ.get('FABRIC_SUDO_PASSWORD', None)
if not SUDO_PASSWORD:
    raise Exception("Set 'FABRIC_SUDO_PASSWORD' env variable to sudo password!") 

# These are the essential three variables upon which the various
# functions of this script is based.
PROJECT = '{{cookiecutter.project_slug}}'
USER_ACCOUNT = '{{cookiecutter.user_name}}'
DOMAIN_NAME = '{{cookiecutter.domain}}'

HOST = '{{cookiecutter.host}}'
PORT = {{cookiecutter.port}}    # pylint: disable=undefined-variable

# Default environment is set for the production server, at {{cookiecutter.domain}}.
# For testing with the staging server, specify the server's hostname from
# fabric command line using the -H argument. For example:-
#
#   fab deploy -H <staging-host>
#
# Omitting the -H <host> would default -H to <DOMAIN_NAME>
# env.port = 64500    # we use non-standard port for better security
# env.hosts = env.hosts if env.hosts else ['hari@{0}:64500'.format(DOMAIN_NAME)]
# env.user = env.user if env.user else 'hari'

# common folders and filepaths
HOME = "/webapps/{{cookiecutter.directory_name}}"
MAINTENANCE_CONF = "{0}/nginx/maintenance.conf".format(HOME)
PRODUCTION_CONF = "{0}/nginx/production.conf".format(HOME)
NGINX_CONF = "/etc/nginx/sites-enabled/{0}".format(PROJECT)
DB_NAME = PROJECT
DB_USER = USER_ACCOUNT

UPGRADE_FILES = [
    'app',
    'requirements'
]

# upgarde type definitions
UPGRADE_INVALID = 0
UPGRADE_MAJOR = 1
UPGRADE_MINOR = 2
UPGRADE_PATCH = 3


@task
def whoami(conn):
    '''Runs 'whoami' at the host.'''
    cfg = conn.config.clone()
    with Connection(HOST, port=PORT, config=cfg) as c:
        c.sudo('whoami', user='{{cookiecutter.user_name}}')
    #conn.run('whoami')


@task
def version(conn):
    '''Runs 'uname -a' at the host.'''
    conn.run('uname -a')



@task
def deploy(ctx):
    '''
    Deploy code to a fresh server. On servers with existing app and associated
    db, the db will wiped out and a new fresh db created in its place.
    Thereafter all the migration scripts will be applied creating the new
    schema.
    '''

    resp = console.confirm("This will DEPLOY {0} to a virgin environment. \n"\
        "If the target environment is not a virgin setup as generated by deploy-django, \n"\
        "this will result in an ERRONEOUS DEPLOYMENT. \n"\
        "ARE YOU SURE?".format(PROJECT), assume_yes=False)
    if not resp:
        exit(1)

    # resp = console.confirm(
    #     "Seriously, is FRESH DEPLOYMENT what you want to do?",
    #     assume_yes=False)
    # if not resp:
    #     exit(1)

    host = ctx.host if hasattr(ctx, 'host') else HOST
    port = ctx.port if hasattr(ctx, 'port') else PORT
    with Connection(host, port=port, config=ctx.config) as conn:
        clean_target(conn)
        upload_scripts(
            conn,
            [ 'prepare_env.sh', 'gunicorn_start.sh', './nginx/' ]
        )
        upload_scripts(
            conn,
            ['./requirements/']
        )

        archive_name = upload_latest_build_to_temp(conn)
        extract_latest_build(conn, archive_name)
        switch_to_uploaded_build(conn)
        install_dependencies(conn)
        collect_staticfiles(conn)

        reset_db(conn)
        prepare_db(conn)
        create_supervisor_conf(conn)
        switch_nginx_to_production(conn)
        conn.sudo('supervisorctl reload')

        print("\nApp successfully deployed!\n")


@task
def update(ctx):
    '''
    Update the latest build folder contents to production/staging server
    depending on the -H argument supplied.

    This command is to be invoked for incremental updates of the server. That
    is, the new code includes migration scripts that can migrate the existing
    database schema to the new schema.

    if -H <host> argument is not supplied, defaults target to live server at
    {{cookiecutter.domain}}.
    '''
    host = ctx.host if hasattr(ctx, 'host') else HOST
    port = ctx.port if hasattr(ctx, 'port') else PORT
    with Connection(host, port=port, config=ctx.config) as conn:

        resp = console.confirm("This will UPDATE the remote server with the contents of 'dist' folder. \n"\
            "ARE YOU SURE?", assume_yes=False)
        if not resp:
            exit(1)

        switch_nginx_to_maintenance(conn)
        stop_appserver(conn)

        # determine upgrade type before we start replacing the files at remote
        # upgrade_t = upgrade_type()

        backup_current_deployment(conn)
        archive_name = upload_latest_build_to_temp(conn)
        extract_latest_build(conn, archive_name)
        switch_to_uploaded_build(conn)

        install_dependencies(conn)
        collect_staticfiles(conn)

        run_migrations(conn)

        start_appserver(conn)
        switch_nginx_to_production(conn)
        remove_old_site_backup(conn)
        #remove_new_site_tempfolder(conn)

        print("\nApp successfully updated!\n")


def clean_target(conn):
    '''Removes any existing file/folders from a previous deploy
    operation. Just in case the previous op failed, and we're
    attempting deployment again.
    '''
    run_as_app_user(
        conn,
        "rm -rf app.new app",
        hide=True
    )
    run_as_app_user(
        conn,
        "rm -rf nginx requirements prepare_env.sh gunicorn_start.sh",
        hide=True
    )


def upload_scripts(conn, SCRIPTS):
    '''
    Upload the scripts in SCRIPTS array to remote. Each entry in the SCRIPTS
    array may be a file (relative to project local folder) or the name of an
    entire folder.
    '''

    archive_filename = 'scripts-{0}.tar.gz'.format(int(datetime.datetime.now().timestamp()))
    temp_folder = tempfile.gettempdir()

    print("Archiving scripts to %s..." % archive_filename)

    conn.local(
        'tar -czf {0} {1}'.format(
            os.path.join(temp_folder, archive_filename),
            ' '.join(SCRIPTS)
        )
    )
    print("Uploading scripts archive...")
    conn.put(os.path.join(temp_folder, archive_filename), '/tmp')

    print("Extracting scripts archive at remote...")
    run_as_app_user(
        conn,
        "tar -xzf /tmp/{0}".format(archive_filename),
        hide=True
    )

    print("Creating .profile for remote user account...")
    # create .profile which loads ./prepare_env.sh so that all sudo -i -u <>
    # will set up the python virtual environment
    run_as_app_user(
        conn,
        "echo \\'source ./prepare_env.sh\\' >> .profile\n",
        hide=True
    )


def install_dependencies(conn):
    '''
    Installs Python package dependencies by running
        pip -r ./requirements/production.txt
    '''
    # compare the requirements folder and if it's contents have
    # changed, invoke pip to install new depedencies
    # import ipdb; ipdb.set_trace()
    # result = run_as_app_user(
    #     conn,
    #     "diff app.old/requirements/base.txt ./requirements/base.txt 2>&1 "\
    #         "&& diff app.old/requirements/production.txt "\
    #         "./requirements/production.txt 2>&1",
    #     hide=True,
    #     warn=True
    # )
    #if not result or result.return_code != 0:
    print("Updating python dependencies...")
    run_as_app_user(
        conn,
        "pip install --trusted-host "\
            "pypi.org --trusted-host files.pythonhosted.org "\
            "-r ./requirements/production.txt --cache-dir /tmp"
    )


def collect_staticfiles(conn):
    ''' Collects static files of all apps to ./static folder. '''
    run_as_app_user(conn, "rm -rf static")
    run_as_app_user(
        conn,
        "cd app && python ./manage.py collectstatic --noinput"
    )


def run_migrations(conn):
    ''' Run all database migrations at remote '''
    run_as_app_user(
        conn,
        "cd app && python ./manage.py migrate"
    )


def switch_to_uploaded_build(conn):
    '''
    Switches the app server code to the new codebase, which is expected to
    be stored in 'new_build_temp_folder' under the HOME folder.
    '''
    run_as_app_user(conn, "mv app.new app")


def backup_current_deployment(conn):
    '''
    Backs up currently deployed code and configuration files to folder
    'dirname'. 'dirname' is taken as relative to site home folder.

    Note that any existing contents of 'dirname' will be destroyed.
    '''
    run_as_app_user(
        conn,
        "rm -rf app.old && mkdir app.old && mv app app.old"
    )


def upload_latest_build_to_temp(conn):
    '''
    Archive's latest build into .tar.gz and uploads this to remote ser ver /tmp
    folder.

    Returns the archive filename.
    '''
    print('Uploading latest build archive to remote...')
    latest_site_archive = archive_current_build(conn)
    conn.put(latest_site_archive, '/tmp')
    return latest_site_archive


def extract_latest_build(conn, archive_name):
    '''
    Extract's uploaded latest build archive into the folder: ~/<PROJECT>.new.

    Note that any existing contents of ~/<PROJECT>.new will be destroyed.
    '''
    print('Extracting latest build archive to ./app.new...')
    run_as_app_user(
        conn,
        "rm -rf app.new &&"\
            "mkdir app.new &&"\
            "tar -xzf /tmp/{0} -C app.new".format(
                os.path.basename(archive_name)
            )
    )


def archive_current_build(conn):
    '''
    Archives the current build folder contents.

    Returns the full filename of the generated .tar.gz file.
    '''
    archive_filename = os.path.join(
        tempfile.gettempdir(),
        '{0}-{1}.tar.gz'.format(PROJECT, build_version()))

    print("Archiving current build to %s..." % archive_filename)

    conn.local('tar -czf {0} -C {1} . '.format(archive_filename, os.path.join('.', 'dist')))
    return archive_filename


def remote_version(conn):
    '''
    Returns the remote's deployed version number.
    '''
    result = run_as_app_user(
        conn,
        "cat ./version.txt | awk '{print $1}'",
        hide=True
    )
    return result.stdout


def build_version():
    '''
    Returns the full version string of current build as "vN.N.N".
    '''
    pkg = json.load(open('./package.json'))
    return "v%s" % pkg['version']


def create_supervisor_conf(conn):
    '''
    Creates the config for supervisord to monitor our app server.
    Assumes that supervisor is installed in the OS, which is done
    by dda.py.
    '''
    conn.sudo('mkdir -p /etc/supervisor', hide=True, warn=True)
    conn.sudo(
        'ln -sf {0}/nginx/supervisor.conf /etc/supervisor/{1}.conf'.format(
            HOME,
            PROJECT
        )
    )


def stop_appserver(conn):
    '''
    Stops Gunicorn app server.
    '''
    conn.sudo('supervisorctl stop {0}'.format(PROJECT))


def start_appserver(conn):
    '''
    Starts Gunicorn app server.
    '''
    conn.sudo('supervisorctl start {0}'.format(PROJECT))


def switch_nginx_to_maintenance(conn):
    '''
    Switches ngnix to maintenance site by pointing it to the site conf that
    maps all site urls to a maintenance html file.
    '''
    conn.sudo('ln -sf %s %s' % (MAINTENANCE_CONF, NGINX_CONF,))
    conn.sudo('nginx -s reload')


def switch_nginx_to_production(conn):
    '''
    Switches ngnix to production site by pointing it to the site conf that
    contains proxy definition for Gunicorn app server.
    '''
    conn.sudo('ln -sf %s %s' % (PRODUCTION_CONF, NGINX_CONF,))
    conn.sudo('nginx -s reload')


def remove_old_site_backup(conn):
    '''
    Removes up the old site that we moved to '<PROJECT>.old'
    '''
    # if all okay, archive the <PROJECT>.old folder where we backed up stuff
    run_as_app_user(
        conn,
        "rm -rf app.old"
    )


def remove_new_site_tempfolder(conn):
    '''
    Removes up the temporary folder where the new site tar.gz was extracted to.
    '''
    run_as_app_user(
        conn,
        "rm -rf app.new"
    )


def upgrade_type(conn):
    '''
    Returns the upgrade type as one of UPGRADE_* constants
    '''
    cur_version = remote_version(conn)
    new_version = build_version()

    if not cur_version:
        exit(1)

    cur_major, cur_minor, cur_patch = cur_version[1:].split('.')
    new_major, new_minor, new_patch = new_version[1:].split('.')

    if new_major > cur_major:
        return UPGRADE_MAJOR

    if new_minor > cur_minor:
        return UPGRADE_MINOR

    if new_patch > cur_patch:
        return UPGRADE_PATCH

    return UPGRADE_INVALID


def reset_db(conn):
    '''
    Reset existing database with a fresh clean on by dropping current one
    and creating a fresh new one.
    '''
    drop_db(conn)
    create_db(conn)


def drop_db(conn):
    ''' Drop the existing database & role '''
    run_as_user(    # DATABASE
        conn,
        'dropdb {0}'.format(DB_NAME),
        'postgres',
        warn=True
    )
    run_as_user(    # ROLE
        conn,
        'dropuser {0}'.format(USER_ACCOUNT),
        'postgres',
        warn=True
    )


def create_db(conn):
    '''Create a new ROLE & database. ROLE password is as set in remote environment variable
    DJANGO_DB_PASSWORD, which is read and used.
    '''
    run_as_user(    # ROLE
        conn,
        'createuser -S -D -R -w {0}'.format(DB_USER),
        'postgres'
    )
    result = run_as_app_user(
        conn,
        'echo $DJANGO_DB_PASSWORD',
        hide=True
    )
    run_as_user(
        conn,
        'psql -c \"ALTER USER {0} WITH PASSWORD \\\'{1}\\\';\"'.format(
            DB_USER,
            result.stdout.split('\n')[0]
        ),
        'postgres'
    )
    run_as_user(    # DATABASE
        conn,
        'createdb {0}'.format(DB_NAME),
        'postgres'
    )
    run_as_user(
        conn,
        'psql -c "GRANT ALL ON DATABASE {0} TO {1}"'.format(DB_NAME, DB_USER),
        'postgres'
    )


def prepare_db(conn):
    '''
    Prepares the database for a fresh deployment by:

        - create the necessary shared schemas
        - loading necessary seed data into the tables.

    Expected to be called within the 'USER_ACCOUNT' user context and with
    environment initialized with the PROJECT virtual environment.
    '''
    run_app_command(conn, 'migrate')


def run_as_user(conn, command, user, *args, **kwargs):
    '''Run the command 'command' in the context of the given user account'''
    return conn.sudo("sudo -i -u {0} bash -c $'{1}'".format(user, command),
        *args,
        **kwargs)


def run_as_app_user(conn, command, *args, **kwargs):
    '''Run the command 'command' in the context of the app user'''
    return run_as_user(conn, command, USER_ACCOUNT, *args, **kwargs)


def run_app_command(conn, command, *args, **kwargs):
    '''Run a python app command.'''
    app_command = 'cd app && python ./manage.py {0}'.format(command)
    return run_as_user(conn, app_command, USER_ACCOUNT, *args, **kwargs)
